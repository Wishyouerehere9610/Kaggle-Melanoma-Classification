{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install efficientnet","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.0-py3-none-any.whl (18 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 1.4 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet) (0.16.2)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\nRequirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.4.1)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (3.2.1)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.4)\nRequirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (7.2.0)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.8.0)\nRequirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.1.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.14.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\nInstalling collected packages: keras-applications, efficientnet\nSuccessfully installed efficientnet-1.1.0 keras-applications-1.0.8\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import re\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom functools import partial\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nimport tempfile\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications import ResNet50\nfrom keras.models import Sequential, Model,load_model\nfrom tensorflow.keras.applications import DenseNet121, DenseNet201\nfrom tensorflow.keras.metrics import AUC, BinaryAccuracy\nfrom tensorflow.keras.losses import BinaryCrossentropy\nimport efficientnet.tfkeras as efn\nfrom random import *\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n    \nprint(tf.__version__)","execution_count":2,"outputs":[{"output_type":"stream","text":"Device: grpc://10.0.0.2:8470\nNumber of replicas: 8\n2.2.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nGCS_PATH = KaggleDatasets().get_gcs_path()\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [1024, 1024]\nIMAGE_RESIZE = [256, 256]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(\n    tf.io.gfile.glob(GCS_PATH + '/tfrecords/train*.tfrec'),\n    test_size=0.1, random_state=5\n)\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/tfrecords/test*.tfrec')\nprint('Train TFRecord Files:', len(TRAINING_FILENAMES))\nprint('Validation TFRecord Files:', len(VALID_FILENAMES))\nprint('Test TFRecord Files:', len(TEST_FILENAMES))","execution_count":4,"outputs":[{"output_type":"stream","text":"Train TFRecord Files: 14\nValidation TFRecord Files: 2\nTest TFRecord Files: 16\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_tfrecord(example, labeled):\n    tfrecord_format = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64)\n    } if labeled else {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    if labeled:\n        label = tf.cast(example['target'], tf.int32)\n        return image, label\n    idnum = example['image_name']\n    return image, idnum","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def augmentation_pipeline(image, label):\n    idx = uniform(1, 10)\n    if (idx<1):\n        image = tf.image.random_flip_left_right(image)\n    elif ((idx>1) and (idx<2)):\n        image = tf.image.random_saturation(image, 5, 10)\n    elif ((idx>2) and (idx<3)):\n        image = tf.image.random_brightness(image, 0.2)\n    image = tf.image.resize(image, IMAGE_RESIZE)\n    return image, label","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.repeat(30)\n#     dataset = dataset.map(augmentation_pipeline, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n#     dataset = dataset.make_initializable_iterator()\n    return dataset","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALID_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nprint(\n    'Dataset: {} training images, {} validation images, {} unlabeled test images'.format(\n        NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES\n    )\n)","execution_count":13,"outputs":[{"output_type":"stream","text":"Dataset: 28984 training images, 4142 validation images, 10982 unlabeled test images\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def build_lrfn(lr_start=0.00001, lr_max=0.000075, lr_min=0.0000001, lr_rampup_epochs=5, lr_sustain_epochs=0, lr_exp_decay=.8):\n#     lr_max = lr_max * strategy.num_replicas_in_sync\n#     def lrfn(epoch):\n#         if epoch < lr_rampup_epochs:\n#             lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n#         elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n#             lr = lr_max\n#         else:\n#             lr = (lr_max - lr_min) * lr_exp_decay ** (epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n#         return lr\n#     return lrfn","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\ntest_csv = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_img = train_csv['target'].size\n\nmalignant = np.count_nonzero(train_csv['target'])\nbenign = total_img - malignant","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = get_training_dataset()\nvalid_dataset = get_validation_dataset()","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_model(output_bias = None, metrics = None):    \n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n        \n    base_model = efn.EfficientNetB7(input_shape=(*IMAGE_RESIZE, 3),\n                                                include_top=False,\n                                                weights='imagenet')\n    \n    base_model.trainable = False\n    \n    model = tf.keras.Sequential([\n        base_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(32,activation=\"relu\"),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(16,activation=\"relu\"),\n        tf.keras.layers.Dense(8,activation=\"relu\"),\n        tf.keras.layers.Dense(1, activation='sigmoid',\n                              bias_initializer=output_bias)\n    ])\n    \n    model.compile(optimizer='adam',\n                  loss='binary_crossentropy',\n                  metrics=metrics)\n    \n    return model\n","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nVALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE\ninitial_bias = np.log([malignant/benign])\nweight_for_0 = (1 / benign)*(total_img)/2.0 \nweight_for_1 = (1 / malignant)*(total_img)/2.0\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nwith strategy.scope():\n    model = make_model(metrics=tf.keras.metrics.AUC(name='auc'),output_bias=initial_bias)\n    \nmodel.summary()","execution_count":19,"outputs":[{"output_type":"stream","text":"Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n258441216/258434480 [==============================] - 3s 0us/step\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nefficientnet-b7 (Model)      (None, 8, 8, 2560)        64097680  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 2560)              0         \n_________________________________________________________________\ndense (Dense)                (None, 32)                81952     \n_________________________________________________________________\ndropout (Dropout)            (None, 32)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 16)                528       \n_________________________________________________________________\ndense_2 (Dense)              (None, 8)                 136       \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 9         \n=================================================================\nTotal params: 64,180,305\nTrainable params: 82,625\nNon-trainable params: 64,097,680\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"callback_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"melanoma_weights.h5\",\n                                                         save_weights_only=True, monitor='val_auc',\n                                                         mode='max', save_best_only = True)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    train_dataset, epochs=30,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=valid_dataset,\n    validation_steps=VALID_STEPS,\n    callbacks = [callback_checkpoint],\n    class_weight=class_weight\n)","execution_count":21,"outputs":[{"output_type":"stream","text":"Epoch 1/30\n226/226 [==============================] - 223s 985ms/step - loss: 1.1133 - auc: 0.4972 - val_loss: 0.5891 - val_auc: 0.6975\nEpoch 2/30\n226/226 [==============================] - 189s 836ms/step - loss: 0.6610 - auc: 0.6741 - val_loss: 0.5148 - val_auc: 0.7828\nEpoch 3/30\n226/226 [==============================] - 190s 839ms/step - loss: 0.6237 - auc: 0.7243 - val_loss: 0.3686 - val_auc: 0.7866\nEpoch 4/30\n226/226 [==============================] - 190s 839ms/step - loss: 0.6500 - auc: 0.7080 - val_loss: 0.5350 - val_auc: 0.8028\nEpoch 5/30\n226/226 [==============================] - 189s 838ms/step - loss: 0.6095 - auc: 0.7450 - val_loss: 0.4653 - val_auc: 0.8103\nEpoch 6/30\n226/226 [==============================] - 185s 819ms/step - loss: 0.5819 - auc: 0.7666 - val_loss: 0.3348 - val_auc: 0.8044\nEpoch 7/30\n226/226 [==============================] - 189s 837ms/step - loss: 0.5589 - auc: 0.7845 - val_loss: 0.3150 - val_auc: 0.8117\nEpoch 8/30\n226/226 [==============================] - 190s 840ms/step - loss: 0.5784 - auc: 0.7774 - val_loss: 0.3193 - val_auc: 0.8119\nEpoch 9/30\n226/226 [==============================] - 190s 841ms/step - loss: 0.5538 - auc: 0.7930 - val_loss: 0.3758 - val_auc: 0.8120\nEpoch 10/30\n226/226 [==============================] - 184s 812ms/step - loss: 0.5650 - auc: 0.7886 - val_loss: 0.3205 - val_auc: 0.8069\nEpoch 11/30\n226/226 [==============================] - 189s 835ms/step - loss: 0.5665 - auc: 0.7964 - val_loss: 0.3472 - val_auc: 0.8191\nEpoch 12/30\n226/226 [==============================] - 185s 817ms/step - loss: 0.5498 - auc: 0.7955 - val_loss: 0.4266 - val_auc: 0.8105\nEpoch 13/30\n226/226 [==============================] - 188s 831ms/step - loss: 0.5364 - auc: 0.8107 - val_loss: 0.3732 - val_auc: 0.8198\nEpoch 14/30\n226/226 [==============================] - 189s 835ms/step - loss: 0.5328 - auc: 0.8068 - val_loss: 0.3308 - val_auc: 0.8251\nEpoch 15/30\n226/226 [==============================] - 184s 814ms/step - loss: 0.5268 - auc: 0.8149 - val_loss: 0.3790 - val_auc: 0.8197\nEpoch 16/30\n226/226 [==============================] - 188s 834ms/step - loss: 0.5370 - auc: 0.8076 - val_loss: 0.3441 - val_auc: 0.8306\nEpoch 17/30\n226/226 [==============================] - 183s 811ms/step - loss: 0.5442 - auc: 0.7950 - val_loss: 0.3347 - val_auc: 0.8208\nEpoch 18/30\n226/226 [==============================] - 184s 812ms/step - loss: 0.5104 - auc: 0.8273 - val_loss: 0.2972 - val_auc: 0.8132\nEpoch 19/30\n226/226 [==============================] - 184s 814ms/step - loss: 0.5287 - auc: 0.8173 - val_loss: 0.3743 - val_auc: 0.8247\nEpoch 20/30\n226/226 [==============================] - 183s 811ms/step - loss: 0.5134 - auc: 0.8268 - val_loss: 0.3245 - val_auc: 0.8234\nEpoch 21/30\n226/226 [==============================] - 184s 814ms/step - loss: 0.5131 - auc: 0.8249 - val_loss: 0.2945 - val_auc: 0.8168\nEpoch 22/30\n226/226 [==============================] - 184s 815ms/step - loss: 0.5133 - auc: 0.8208 - val_loss: 0.3003 - val_auc: 0.8225\nEpoch 23/30\n226/226 [==============================] - 183s 812ms/step - loss: 0.5297 - auc: 0.8174 - val_loss: 0.2893 - val_auc: 0.8196\nEpoch 24/30\n226/226 [==============================] - 184s 812ms/step - loss: 0.5195 - auc: 0.8192 - val_loss: 0.2940 - val_auc: 0.8181\nEpoch 25/30\n226/226 [==============================] - 184s 815ms/step - loss: 0.5077 - auc: 0.8277 - val_loss: 0.3523 - val_auc: 0.8260\nEpoch 26/30\n226/226 [==============================] - 183s 810ms/step - loss: 0.5120 - auc: 0.8265 - val_loss: 0.3299 - val_auc: 0.8161\nEpoch 27/30\n226/226 [==============================] - 184s 816ms/step - loss: 0.5068 - auc: 0.8295 - val_loss: 0.3153 - val_auc: 0.8173\nEpoch 28/30\n226/226 [==============================] - 184s 815ms/step - loss: 0.5209 - auc: 0.8235 - val_loss: 0.2692 - val_auc: 0.8055\nEpoch 29/30\n226/226 [==============================] - 184s 814ms/step - loss: 0.5112 - auc: 0.8273 - val_loss: 0.2730 - val_auc: 0.8171\nEpoch 30/30\n226/226 [==============================] - 183s 811ms/step - loss: 0.5035 - auc: 0.8355 - val_loss: 0.3664 - val_auc: 0.8121\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ds = get_test_dataset(ordered=True)\n\nprint('Computing predictions...')\ntest_images_ds = test_ds.map(lambda image, idnum: image)\nprobabilities = model.predict(test_images_ds)","execution_count":22,"outputs":[{"output_type":"stream","text":"Computing predictions...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = pd.DataFrame({'image_name': test_ids, 'target': np.concatenate(probabilities)})\npred_df.head()","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"     image_name    target\n0  ISIC_6381819  0.448703\n1  ISIC_5583376  0.626561\n2  ISIC_6408546  0.039798\n3  ISIC_6932354  0.308564\n4  ISIC_8191278  0.170549","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_6381819</td>\n      <td>0.448703</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_5583376</td>\n      <td>0.626561</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_6408546</td>\n      <td>0.039798</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_6932354</td>\n      <td>0.308564</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_8191278</td>\n      <td>0.170549</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv\")","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del sub['target']\nsub = sub.merge(pred_df, on='image_name')\nsub.to_csv('submission.csv', index=False)\nsub.head()","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"     image_name    target\n0  ISIC_0052060  0.031655\n1  ISIC_0052349  0.027625\n2  ISIC_0058510  0.030385\n3  ISIC_0073313  0.037714\n4  ISIC_0073502  0.604788","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0052060</td>\n      <td>0.031655</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0052349</td>\n      <td>0.027625</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0058510</td>\n      <td>0.030385</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0073313</td>\n      <td>0.037714</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0073502</td>\n      <td>0.604788</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}